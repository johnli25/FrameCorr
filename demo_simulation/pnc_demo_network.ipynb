{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe5c1d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e371012-48ed-4082-a287-17aecbabb58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2160d1dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 13:00:17.420250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.453088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.453248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157fe43a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_save_folder = \"./joint_ae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3c1d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of imgs in the folder: 50000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "img_folder = \"./val2017/\"\n",
    "img_paths = sorted(glob.glob(img_folder+'/*'))\n",
    "# print(img_paths)\n",
    "print(\"Number of imgs in the folder:\", len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c401b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "label_path = './data/ImageNetLabels.txt'\n",
    "with open(label_path, \"r\", encoding=\"UTF8\") as lbfile:\n",
    "    labels = lbfile.read().splitlines()\n",
    "\n",
    "# ground truths\n",
    "gt_path = './data/caffe_clsloc_validation_ground_truth.txt'\n",
    "with open(gt_path,\"r\") as lbfile:\n",
    "    lines = lbfile.readlines()\n",
    "    gts = []\n",
    "    for x in lines:\n",
    "        gts.append(int(x.split(' ')[1].splitlines()[0]))\n",
    "# gts = np.array(gts) + 1\n",
    "gts = np.array(gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22d58d",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98e7fe",
   "metadata": {},
   "source": [
    "### Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6207b183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "C = 1e-4\n",
    "\n",
    "def orthogonal_reg(w):  # 1703.01827\n",
    "  units = w.shape[-1]\n",
    "  w = tf.reshape(w, (-1, units))\n",
    "  w = tf.transpose(w) @ w\n",
    "  \n",
    "  return (C/2)*tf.linalg.norm(w - tf.eye(units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe1c0a",
   "metadata": {},
   "source": [
    "### Prepare Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de545cfc-c306-4031-af36-dbc427a3436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4c8631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 224\n",
      "Model: \"enocder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 112, 112, 32)      2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 56, 56, 16)        12816     \n",
      "                                                                 \n",
      " encoder_out (Conv2D)        (None, 28, 28, 13)        1885      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,133\n",
      "Trainable params: 17,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 13:00:17.620397: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-15 13:00:17.620912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.621044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.621123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.964986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.965108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.965189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-15 13:00:17.965262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22269 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(img_height, img_width)\n",
    "\n",
    "encoder_input = layers.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "# Encoder\n",
    "initializer = tf.keras.initializers.Orthogonal()\n",
    "encoder_x = layers.Conv2D(32, (5, 5), \n",
    "                  strides=2, \n",
    "                  activation=\"relu\", \n",
    "                  padding=\"same\", \n",
    "                  kernel_initializer=initializer\n",
    "                 )(encoder_input)\n",
    "\n",
    "encoder_x = layers.Conv2D(16, (5, 5), \n",
    "                  strides=2, \n",
    "                  activation=\"relu\", \n",
    "                  padding=\"same\", \n",
    "                  kernel_initializer=initializer\n",
    "                 )(encoder_x)\n",
    "encoder_x = layers.Conv2D(13, (3, 3), \n",
    "                strides=2,\n",
    "                  activation=\"relu\", \n",
    "                  padding=\"same\", \n",
    "                  kernel_initializer=initializer,\n",
    "                  name='encoder_out'\n",
    "                 )(encoder_x)\n",
    "\n",
    "encoder_model = keras.Model(encoder_input, encoder_x,  name='enocder')\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "481fe471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_tail(X):\n",
    "    total_dim = tf.shape(X)[-1]\n",
    "    tail_len = tf.random.uniform([1,], minval=0, maxval=total_dim, dtype=tf.int32)\n",
    "    tail_len = tf.math.minimum(tail_len, total_dim)\n",
    "    head_len = total_dim - tail_len\n",
    "    mask = tf.concat((tf.ones([tf.shape(X)[1], tf.shape(X)[2], head_len[0]]), tf.zeros((tf.shape(X)[1], tf.shape(X)[2],tail_len[0]))), axis=-1)\n",
    "    X = X*mask\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af3b52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 13)]      0         \n",
      "                                                                 \n",
      " decoder_input (Conv2DTransp  (None, 56, 56, 128)      6784      \n",
      " ose)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 112, 112, 64)     73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 224, 224, 32)     51232     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 3)       867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,675\n",
      "Trainable params: 132,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "_,w,h,c = encoder_model.get_layer('encoder_out').output_shape\n",
    "decoder_input = layers.Input(shape=(w,h,c))\n",
    "decoder_x = layers.Conv2DTranspose(128, (2, 2), \n",
    "                                   strides=2, \n",
    "                                   activation=\"relu\", \n",
    "                                   padding=\"same\",\n",
    "                                   name=\"decoder_input\"\n",
    "                                                          )(decoder_input)\n",
    "decoder_x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(decoder_x)\n",
    "decoder_x = layers.Conv2DTranspose(32, (5, 5), strides=2, activation=\"relu\",padding=\"same\")(decoder_x)\n",
    "decoder_x = layers.Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(decoder_x)    \n",
    "# Autoencoder\n",
    "decoder_model = keras.Model(decoder_input, decoder_x,  name='decoder')\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac889e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1658253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainStep(tf.keras.Model):\n",
    "    def __init__(self, n_gradients, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n_gradients = tf.constant(n_gradients, dtype=tf.int32)\n",
    "        self.n_acum_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), trainable=False) for v in self.trainable_variables]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        self.n_acum_step.assign_add(1)\n",
    "\n",
    "        x, y = data\n",
    "        # Gradient Tape\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        # Calculate batch gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        # Accumulate batch gradients\n",
    "        for i in range(len(self.gradient_accumulation)):\n",
    "            self.gradient_accumulation[i].assign_add(gradients[i])\n",
    " \n",
    "        # If n_acum_step reach the n_gradients then we apply accumulated gradients to update the variables otherwise do nothing\n",
    "        tf.cond(tf.equal(self.n_acum_step, self.n_gradients), self.apply_accu_gradients, lambda: None)\n",
    "\n",
    "        # update metrics\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def apply_accu_gradients(self):\n",
    "        # apply accumulated gradients\n",
    "        self.optimizer.apply_gradients(zip(self.gradient_accumulation, self.trainable_variables))\n",
    "\n",
    "        # reset\n",
    "        self.n_acum_step.assign(0)\n",
    "        for i in range(len(self.gradient_accumulation)):\n",
    "            self.gradient_accumulation[i].assign(tf.zeros_like(self.trainable_variables[i], dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa9744c-3e94-438a-8093-c62a559760dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f9bdca4bd90> and <keras.engine.input_layer.InputLayer object at 0x7f9bdcaab370>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.layers.convolutional.Conv2D object at 0x7f9bdca4bd90> and <keras.engine.input_layer.InputLayer object at 0x7f9bdcaab370>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9bdc118460>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.load_weights(model_save_folder + \"/best_model_save_encoder/variables/variables\")\n",
    "encoder_model.load_weights(model_save_folder + \"/best_model_save_decoder/variables/variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4732c2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " enocder (Functional)           (None, 28, 28, 13)   17133       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (4,)                0           ['enocder[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.random.uniform (TFOpLambda)  (1,)                0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.math.minimum (TFOpLambda)   (1,)                 0           ['tf.random.uniform[0][0]',      \n",
      "                                                                  'tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOpLamb  (4,)                0           ['enocder[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_2 (TFOpLamb  (4,)                0           ['enocder[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (1,)                 0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.math.minimum[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_3 (TFOpLamb  (4,)                0           ['enocder[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_4 (TFOpLamb  (4,)                0           ['enocder[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  ()                  0           ['tf.math.subtract[0][0]']       \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  ()                  0           ['tf.compat.v1.shape_3[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  ()                  0           ['tf.compat.v1.shape_4[0][0]']   \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  ()                  0           ['tf.math.minimum[0][0]']        \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.ones (TFOpLambda)           (28, 28, None)       0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.zeros (TFOpLambda)          (28, 28, None)       0           ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (28, 28, None)       0           ['tf.ones[0][0]',                \n",
      "                                                                  'tf.zeros[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 28, 28, 13)   0           ['enocder[0][0]',                \n",
      "                                                                  'tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 224, 224, 3)  132675      ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 149,808\n",
      "Trainable params: 149,808\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ae = layers.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "e_out = encoder_model(input_ae)\n",
    "e_out = dropout_tail(e_out)\n",
    "d_out = decoder_model(e_out)\n",
    "\n",
    "autoencoder_model = keras.Model(inputs=[input_ae], outputs=[d_out], name=\"ae_model\")\n",
    "# autoencoder_model = CustomTrainStep(n_gradients=5, inputs=[input_ae], outputs=[d_out], name=\"ae_model\")\n",
    "autoencoder_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse')\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66770134",
   "metadata": {},
   "source": [
    "## Split the Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8251359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cut_encoder_decoder(autoencoder_model, layerName = \"decoder\", verbose=False):\n",
    "    decoder_input_index = None\n",
    "#     layerName = layerName\n",
    "    for idx, layer in enumerate(autoencoder_model.layers):\n",
    "        if layer.name == layerName:\n",
    "            decoder_input_index = idx\n",
    "            break\n",
    "\n",
    "    if verbose: print(\"Decoder index:\", decoder_input_index,\"\\n---\")\n",
    "\n",
    "    # encoder = keras.Model(autoencoder_tail_model.get_layer(\"input_4\").input, autoencoder_tail_model.get_layer(\"encoder\").output, name='encoder1')\n",
    "\n",
    "    encoder = tf.keras.Sequential(name='encoder1')\n",
    "    for layer in autoencoder_model.layers[:2]:\n",
    "        encoder.add(layer)\n",
    "\n",
    "    # encoder.compile()\n",
    "    if verbose: encoder.summary()\n",
    "\n",
    "    decoder = tf.keras.Sequential(name='decoder1')\n",
    "    for layer in autoencoder_model.layers[decoder_input_index:]:\n",
    "        decoder.add(layer)\n",
    "\n",
    "\n",
    "    # encoder.compile()\n",
    "    if verbose: decoder.summary()\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c3360c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder index: 21 \n",
      "---\n",
      "Model: \"encoder1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " enocder (Functional)        (None, 28, 28, 13)        17133     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,133\n",
      "Trainable params: 17,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder (Functional)        (None, 224, 224, 3)       132675    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,675\n",
      "Trainable params: 132,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_pnc, decoder_pnc = cut_encoder_decoder(autoencoder_model, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:edge_rateless]",
   "language": "python",
   "name": "conda-env-edge_rateless-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "844px",
    "left": "1852px",
    "right": "20px",
    "top": "108px",
    "width": "669px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
